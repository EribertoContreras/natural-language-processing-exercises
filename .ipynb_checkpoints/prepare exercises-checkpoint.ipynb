{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d0be7c",
   "metadata": {},
   "source": [
    "## The end result of this exercise should be a file named `prepare.py` that defines the requested functions.\n",
    "\n",
    "**In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.**\n",
    "\n",
    "1) Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "\n",
    "2) Define a function named `tokenize`. It should take in a string and tokenize all the words in the string.\n",
    "\n",
    "3) Define a function named `stem`. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n",
    "4) Define a function named `lemmatize`. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n",
    "5) Define a function named `remove_stopwords`. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "\n",
    "6) Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.\n",
    "\n",
    "7) Make another dataframe for the Codeup blog posts. Name the dataframe `codeup_df`.\n",
    "\n",
    "8) For each dataframe, produce the following columns:\n",
    "\n",
    "- `title` to hold the title\n",
    "- `original` to hold the original article/post content\n",
    "- `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- `stemmed` to hold the stemmed version of the cleaned data.\n",
    "- `lemmatized` to hold the lemmatized version of the cleaned data.\n",
    "\n",
    "9) Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd9c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7907b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/albertcontreras/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't need to install nltk, it should come with anaconda, but nltk\n",
    "# does need to download some data.\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c6fed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/albertcontreras/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99abd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the Math and Stats Principles You Need for Data Science?\n",
      "Oct 21, 2020 | Data Science\n",
      "\n",
      "\n",
      "Coming into our Data Science program, you will need to know some math and stats. However, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! Data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. But what “skills” do we mean, e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examples \n",
    "original = \"\"\"What are the Math and Stats Principles You Need for Data Science?\n",
    "Oct 21, 2020 | Data Science\n",
    "\n",
    "\n",
    "Coming into our Data Science program, you will need to know some math and stats. However, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! Data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. But what “skills” do we mean, e\n",
    "\"\"\"\n",
    "print(original[0:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e05918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stats principles you need for data science?\n",
      "oct 21, 2020 | data science\n",
      "\n",
      "\n",
      "coming into our data science program, you will need to know some math and stats. however, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. but what “skills” do we mean, e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = original.lower()\n",
    "print(article[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697fa44",
   "metadata": {},
   "source": [
    "# REMOVING ACCENTED CHARACTERS\n",
    "1) `unicodedata.normalize` removes any inconsistencies in unicode character encoding.\n",
    "\n",
    "2) `.encode` to convert the resulting string to the ASCII character set. We'll ignore any errors in conversion, meaning we'll drop anything that isn't an ASCII character.\n",
    "\n",
    "3) `.decode` to turn the resulting bytes object back into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23add00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stats principles you need for data science?\n",
      "oct 21, 2020 | data science\n",
      "\n",
      "\n",
      "coming into our data science program, you will need to know some math and stats. however, many of our applicants actually learn in the application process  you dont need to be an expert before applying! data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. but what skills do we mean, e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "print(article[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c258a25",
   "metadata": {},
   "source": [
    "# REMOVING SPECIAL CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1905492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stats principles you need for data science\n",
      "oct 21 2020  data science\n",
      "\n",
      "\n",
      "coming into our data science program you will need to know some math and stats however many of our applicants actually learn in the application process  you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skills and we can work with any applicant to help them learn what they need to know but what skills do we mean e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132e0af",
   "metadata": {},
   "source": [
    "# TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a214c212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stats principles you need for data science\n",
      "oct 21 2020 data science\n",
      "\n",
      "\n",
      "coming into our data science program you will need to know some math and stats however many of our applicants actually learn in the application process you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skills and we can work with any applicant to help them learn what they need to know but what skills do we mean e\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(article, return_str=True)[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eff454",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7662d41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "ps.stem('call'), ps.stem('called'), ps.stem('calling')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d9af74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stat principl you need for data scienc oct 21 2020 data scienc come into our data scienc program you will need to know some math and stat howev mani of our applic actual learn in the applic process you dont need to be an expert befor appli data scienc is a veri access field to anyon dedic to learn new skill and we can work with ani applic to help them learn what they need to know but what skill do we mean e\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in article.split()]\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(article_stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b133246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to        6\n",
       "need      4\n",
       "data      4\n",
       "scienc    4\n",
       "what      3\n",
       "learn     3\n",
       "applic    3\n",
       "and       3\n",
       "you       3\n",
       "skill     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26d387",
   "metadata": {},
   "source": [
    "# [SEE CLASS LINK FOR MORE HELP](https://ds.codeup.com/nlp/prepare/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c9caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string we will be testing on.\n",
    "test_code = \"\"\"What are the Math and Stats Principles You Need for Data Science?\n",
    "Oct 21, 2020 | Data Science\n",
    "Coming into our Data Science program, you will need to know some math and stats. However, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! Data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. But what “skills” do we mean, e\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed95d6",
   "metadata": {},
   "source": [
    "1) Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121167f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the math and stats principles you need for data science\\noct 21 2020  data science\\ncoming into our data science program you will need to know some math and stats however many of our applicants actually learn in the application process  you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skills and we can work with any applicant to help them learn what they need to know but what skills do we mean e\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_clean(string):\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "        .encode('ascii', 'ignore')\\\n",
    "        .decode('utf-8', 'ignore')\\\n",
    "        .lower()\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)                                \n",
    "    return string\n",
    "basic_clean(test_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "254f7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated = basic_clean(test_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989aa49d",
   "metadata": {},
   "source": [
    "2) Define a function named `tokenize`. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "696c6a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the math and stats principles you need for data science\\noct 21 2020 data science\\ncoming into our data science program you will need to know some math and stats however many of our applicants actually learn in the application process you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skills and we can work with any applicant to help them learn what they need to know but what skills do we mean e'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(string):\n",
    "    #define tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # apply tokenization to the string.\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    #return tokenized string.\n",
    "    return string\n",
    "tokenize(updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446a541",
   "metadata": {},
   "source": [
    "3) Define a function named `stem`. It should accept some text and return the text after applying stemming to all the words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "042a5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string) :\n",
    "    \"\"\"This function returns a string in stemmed format.\"\"\"\n",
    "    # create our stemming\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # split by the default\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    # return to normal\n",
    "    string = ' '.join(stems)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893a3bd",
   "metadata": {},
   "source": [
    "4) Define a function named `lemmatize`. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99540e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the math and stat principl you need for data scienc oct 21 2020 data scienc come into our data scienc program you will need to know some math and stat howev mani of our applic actual learn in the applic process you dont need to be an expert befor appli data scienc is a veri access field to anyon dedic to learn new skill and we can work with ani applic to help them learn what they need to know but what skill do we mean e'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenize(updated)\n",
    "stem(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e7599eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \"\"\"This function returns a string with words lemmatized\"\"\"\n",
    "    # create our lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # use a list. comprehension to lemmatize each word\n",
    "    # string.split() => output a list of every token inside of the document\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    # glue the lemmas back together by the strings we split on\n",
    "    string= ' '.join(lemmas)\n",
    "    #return the altered document\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8834768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the math and stats principle you need for data science oct 21 2020 data science coming into our data science program you will need to know some math and stats however many of our applicant actually learn in the application process you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skill and we can work with any applicant to help them learn what they need to know but what skill do we mean e'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac18503",
   "metadata": {},
   "source": [
    "5) Define a function named `remove_stopwords`. It should accept some text and return the text after removing all the stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdfba573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords (string, extra_words = [], exclude_words = []):\n",
    "    \"This function takes in a string, optional extra_words and exclude_words parameters\"\n",
    "    # assian our stoowords from nltk into stooword list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # utilizing set casting, i will remove any excluded stopwords\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    # add in any extra words to my stopwords set using a union\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    #split document by spaces\n",
    "    words = string.split()\n",
    "    # every word in our document, as long as that word is not in our stopwords\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    # glue it back together with spaces, as it was so it shall be\n",
    "    string_without_stopwords =' '.join(filtered_words)\n",
    "    # return the document back\n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b292783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'math stats principles need data science oct 21 2020 data science coming data science program need know math stats however many applicants actually learn application process dont need expert applying data science accessible field anyone dedicated learning new skills work applicant help learn need know skills mean e'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a171bb",
   "metadata": {},
   "source": [
    "6) Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f386188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Situation is exceptional but comparing it with...</td>\n",
       "      <td>The government hosted an all-party meeting on ...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fires erupt across UK as it records its hottes...</td>\n",
       "      <td>The south of England and Wales saw multiple fi...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hottest day recorded in history of UK as tempe...</td>\n",
       "      <td>The hottest day has been recorded in the histo...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russia seeks explanation from India over detai...</td>\n",
       "      <td>Russian Embassy in India has said it's aware o...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India &amp; China to maintain stability along LAC ...</td>\n",
       "      <td>India and China agreed to maintain stability o...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nick Jonas shares pics from Priyanka's b'day, ...</td>\n",
       "      <td>Singer-actor Nick Jonas shared pictures of act...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Had to deliver, so they come for more talent f...</td>\n",
       "      <td>Actor Dhanush has said he wasn't nervous to wo...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Still here, in our hearts: Twinkle on dad Raje...</td>\n",
       "      <td>Actress-turned-writer Twinkle Khanna penned a ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>List of debtors after Sanjeev Kumar's death mi...</td>\n",
       "      <td>Actor Sanjeev Kumar's sister-in-law Jyoti Niku...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Manushi joins John in 'Tehran', says 'This is ...</td>\n",
       "      <td>Manushi Chhillar has been roped in to star opp...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Situation is exceptional but comparing it with...   \n",
       "1   Fires erupt across UK as it records its hottes...   \n",
       "2   Hottest day recorded in history of UK as tempe...   \n",
       "3   Russia seeks explanation from India over detai...   \n",
       "4   India & China to maintain stability along LAC ...   \n",
       "..                                                ...   \n",
       "19  Nick Jonas shares pics from Priyanka's b'day, ...   \n",
       "20  Had to deliver, so they come for more talent f...   \n",
       "21  Still here, in our hearts: Twinkle on dad Raje...   \n",
       "22  List of debtors after Sanjeev Kumar's death mi...   \n",
       "23  Manushi joins John in 'Tehran', says 'This is ...   \n",
       "\n",
       "                                             contents       category  \n",
       "0   The government hosted an all-party meeting on ...          world  \n",
       "1   The south of England and Wales saw multiple fi...          world  \n",
       "2   The hottest day has been recorded in the histo...          world  \n",
       "3   Russian Embassy in India has said it's aware o...          world  \n",
       "4   India and China agreed to maintain stability o...          world  \n",
       "..                                                ...            ...  \n",
       "19  Singer-actor Nick Jonas shared pictures of act...  entertainment  \n",
       "20  Actor Dhanush has said he wasn't nervous to wo...  entertainment  \n",
       "21  Actress-turned-writer Twinkle Khanna penned a ...  entertainment  \n",
       "22  Actor Sanjeev Kumar's sister-in-law Jyoti Niku...  entertainment  \n",
       "23  Manushi Chhillar has been roped in to star opp...  entertainment  \n",
       "\n",
       "[97 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import acquire\n",
    "categories = ['world', 'science', 'technology', 'entertainment']\n",
    "news_df = acquire.get_shorts_articles(categories, refresh = False)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0bb35c",
   "metadata": {},
   "source": [
    "7) Make another dataframe for the Codeup blog posts. Name the dataframe `codeup_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff4eb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertcontreras/codeup-data-science/natural-language-processing-exercises/acquire.py:35: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 35 of the file /Users/albertcontreras/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(url_response.text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Have you been considering a career in Cloud Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>If you are interested in embarking on a career...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Our Cloud Administration Program Right for ...</td>\n",
       "      <td>Changing careers can be scary. The first thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Reasons To Attend Our New Cloud Administrati...</td>\n",
       "      <td>Come Work In The Cloud\\nWhen your Monday rolls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Have you been considering a career in Cloud Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>If you are interested in embarking on a career...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In-Person Workshop: Learn to Code – JavaScript...</td>\n",
       "      <td>Join us for our live in-person JavaScript cras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In-Person Workshop: Learn to Code – Python on ...</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Free JavaScript Workshop at Codeup Dallas on 6/28</td>\n",
       "      <td>Event Info: \\nLocation – Codeup Dallas\\nTime –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Is Our Cloud Administration Program Right for ...</td>\n",
       "      <td>Changing careers can be scary. The first thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRIDE in Tech Panel</td>\n",
       "      <td>In celebration of PRIDE month, join our Codeup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Inclusion at Codeup During Pride Month (and Al...</td>\n",
       "      <td>Happy Pride Month! Pride Month is a dedicated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mental Health First Aid Training</td>\n",
       "      <td>As a student of Codeup, going through a massiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Codeup Dallas: How to Succeed at a Coding Boot...</td>\n",
       "      <td>This event is the perfect opportunity for peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5 Reasons To Attend Our New Cloud Administrati...</td>\n",
       "      <td>Come Work In The Cloud\\nWhen your Monday rolls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Learn to Code: Python on 5/21</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Codeup Dallas Joins Career Day</td>\n",
       "      <td>Last week our Codeup Dallas team participated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Project Quest Info Session: IT Jumpstart on Ma...</td>\n",
       "      <td>Join our grant partner Project Quest as they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>From Bootcamp to Bootcamp | A Military Appreci...</td>\n",
       "      <td>In honor of Military Appreciation Month, join ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Our Acquisition of the Rackspace Cloud Academy...</td>\n",
       "      <td>Just about a year ago on April 16th, 2021 we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Learn to Code: HTML &amp; CSS on 4/30</td>\n",
       "      <td>HTML &amp; CSS are the design building blocks of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   What Jobs Can You Get After a Coding Bootcamp?...   \n",
       "1   What Jobs Can You Get After a Coding Bootcamp?...   \n",
       "2   Is Our Cloud Administration Program Right for ...   \n",
       "3   5 Reasons To Attend Our New Cloud Administrati...   \n",
       "4   What Jobs Can You Get After a Coding Bootcamp?...   \n",
       "5   What Jobs Can You Get After a Coding Bootcamp?...   \n",
       "6   In-Person Workshop: Learn to Code – JavaScript...   \n",
       "7   In-Person Workshop: Learn to Code – Python on ...   \n",
       "8   Free JavaScript Workshop at Codeup Dallas on 6/28   \n",
       "9   Is Our Cloud Administration Program Right for ...   \n",
       "10                                PRIDE in Tech Panel   \n",
       "11  Inclusion at Codeup During Pride Month (and Al...   \n",
       "12                   Mental Health First Aid Training   \n",
       "13  Codeup Dallas: How to Succeed at a Coding Boot...   \n",
       "14  5 Reasons To Attend Our New Cloud Administrati...   \n",
       "15                      Learn to Code: Python on 5/21   \n",
       "16                     Codeup Dallas Joins Career Day   \n",
       "17  Project Quest Info Session: IT Jumpstart on Ma...   \n",
       "18  From Bootcamp to Bootcamp | A Military Appreci...   \n",
       "19  Our Acquisition of the Rackspace Cloud Academy...   \n",
       "20                  Learn to Code: HTML & CSS on 4/30   \n",
       "21             Learn to Code: Python Workshop on 4/23   \n",
       "\n",
       "                                              content  \n",
       "0   Have you been considering a career in Cloud Ad...  \n",
       "1   If you are interested in embarking on a career...  \n",
       "2   Changing careers can be scary. The first thing...  \n",
       "3   Come Work In The Cloud\\nWhen your Monday rolls...  \n",
       "4   Have you been considering a career in Cloud Ad...  \n",
       "5   If you are interested in embarking on a career...  \n",
       "6   Join us for our live in-person JavaScript cras...  \n",
       "7   According to LinkedIn, the “#1 Most Promising ...  \n",
       "8   Event Info: \\nLocation – Codeup Dallas\\nTime –...  \n",
       "9   Changing careers can be scary. The first thing...  \n",
       "10  In celebration of PRIDE month, join our Codeup...  \n",
       "11  Happy Pride Month! Pride Month is a dedicated ...  \n",
       "12  As a student of Codeup, going through a massiv...  \n",
       "13  This event is the perfect opportunity for peop...  \n",
       "14  Come Work In The Cloud\\nWhen your Monday rolls...  \n",
       "15  According to LinkedIn, the “#1 Most Promising ...  \n",
       "16  Last week our Codeup Dallas team participated ...  \n",
       "17  Join our grant partner Project Quest as they d...  \n",
       "18  In honor of Military Appreciation Month, join ...  \n",
       "19  Just about a year ago on April 16th, 2021 we a...  \n",
       "20  HTML & CSS are the design building blocks of a...  \n",
       "21  According to LinkedIn, the “#1 Most Promising ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = acquire.blog_articles()\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b8d53",
   "metadata": {},
   "source": [
    "8) For each dataframe, produce the following columns:\n",
    "\n",
    "- `title` to hold the title\n",
    "- `original` to hold the original article/post content\n",
    "- `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- `stemmed` to hold the stemmed version of the cleaned data.\n",
    "- `lemmatized` to hold the lemmatized version of the cleaned data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.rename(columns={'content':'original'},inplace=True)\n",
    "codeup_df.rename(columns={'content':'original'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd62e9",
   "metadata": {},
   "source": [
    "9) Ask yourself:\n",
    "\n",
    "`a) If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?`\n",
    "\n",
    "`b) If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?`\n",
    "\n",
    "`c) If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d8c4fe",
   "metadata": {},
   "source": [
    "    a) stemmed or lemmetized because it is not a big file\n",
    "\n",
    "    b) lemmetized because it is still not that big of data\n",
    "\n",
    "    c) stemmed because the file is too big and it will save processing time and spcaee(money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24f505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
